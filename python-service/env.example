# Server Configuration
HOST=0.0.0.0
PORT=5000
DEBUG=false

# Note: CORS is not needed here - this is an internal service
# Only the Go backend communicates with this service
# CORS is configured on the Go backend

# Model Configuration
# For 3B: Qwen/Qwen2.5-3B-Instruct (quantization: none)
# For 7B: Qwen/Qwen2.5-7B-Instruct (quantization: 4bit)
MODEL_NAME=Qwen/Qwen2.5-3B-Instruct
HUGGINGFACE_TOKEN=your_token_here
DEVICE=cuda
QUANTIZATION=none
DTYPE=bfloat16

# Generation Parameters
MAX_NEW_TOKENS=512
TEMPERATURE=0.6
TOP_P=0.9
REPETITION_PENALTY=1.1
CONTEXT_WINDOW=32768

# Streaming Configuration
CHUNK_SIZE=10
DELAY_MS=50
BUFFER_SIZE=100

# Backend Integration
BACKEND_URL=http://localhost:8080

# Model Config File
MODEL_CONFIG_PATH=config/model_config.yaml

