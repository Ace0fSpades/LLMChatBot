# Python LLM Service

Внутренний микросервис для генерации ответов с использованием языковых моделей.

## Важно

Это **внутренний сервис**, к которому обращается только Go бэкенд. Клиенты (браузеры) не имеют прямого доступа к этому сервису. CORS настроен только на Go бэкенде.

## Архитектура

Сервис следует архитектуре, согласованной с бэкендом Go:
- **API Layer** - FastAPI endpoints
- **Service Layer** - бизнес-логика и inference engine
- **Model Layer** - управление моделями и токенизаторами
- **Integration Layer** - интеграция с Go сервисом
- **Monitoring Layer** - метрики и логирование

## Запуск

```bash
# Установка зависимостей
pip install -r requirements.txt

# Запуск сервиса
uvicorn app.main:app --host 0.0.0.0 --port 5000
```

## Конфигурация

Создайте файл `.env` на основе `env.example` и `config/model_config.yaml` для настройки модели.

