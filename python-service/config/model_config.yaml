# Model Configuration
model:
  name: "Qwen/Qwen2.5-3B-Instruct"  # For 7B: "Qwen/Qwen2.5-7B-Instruct"
  
  quantization: "8bit"  # "4bit" (for 7B), "8bit", or "none" (for 3B)
  device: "cuda"       # "cuda" or "cpu"
  dtype: "bfloat16"    # "float16", "bfloat16" (recommended for Qwen), or "float32"
  
  context_window: 32768  # Qwen 2.5 supports up to 32K context
  max_new_tokens: 2048  # Increased for longer responses
  temperature: 0.6      # Balanced for chat
  top_p: 0.9
  repetition_penalty: 1.1

# Streaming Configuration
streaming:
  chunk_size: 10       # tokens per chunk
  delay_ms: 50         # delay between chunks in milliseconds
  buffer_size: 100     # token buffer size

# Prompt Template
prompt_template: |
  <|system|>
  You are a helpful AI assistant. Answer the user's questions clearly and concisely.
  
  Previous conversation:
  {history}
  
  <|user|>
  {question}
  
  <|assistant|>

